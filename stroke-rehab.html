<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mixed Reality Stroke Rehabilitation - Jeremy Fischer</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="carousel.css">
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-link">← Back to Portfolio</a>
        
        <div class="hero-section">
            <h1 class="hero-title">Mixed Reality Stroke Rehabilitation</h1>
            <div class="hero-subtitle">UC Berkeley | UCSF | Stanford</div>
            <div class="hero-date">March 2025 - Present</div>
            
            <!-- PROJECT CAROUSEL -->
            <div class="carousel-container" data-carousel="wargame" data-auto-advance="false" data-auto-advance-time="6000">
                <div class="carousel-wrapper">
                    <div class="carousel-slides">
                        <div class="carousel-slide square-video active">
                            <video controls muted autoplay loop>
                                <source src="images/stroke-rehab/Showcase Video.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">Exercises being performed in mixed reality</div>
                        </div>
                        <div class="carousel-slide active">
                            <video controls muted autoplay loop>
                                <source src="images/stroke-rehab/TODO.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div class="caption">Remote therapy sessions give therapist a unique first person view, 3rd person virtual reconstruction, and virtual object catalog for conducting exercises.</div>
                        </div>
                        <div class="carousel-slide">
                            <div class="placeholder"><img src="images/stroke-rehab/exercise history.png" alt=""></div>
                            <div class="caption">Patient's exercise history and progress tracking interface</div>
                        </div>
                        <div class="carousel-slide">
                            <div class="placeholder"><img src="images/stroke-rehab/worksheet 2.png" alt=""></div>
                            <div class="caption">Therapists can create exercises from natural language, tweaking to the patient's ability and need, which is turned into software for headset.</div>
                        </div>
                    </div>
                    
                    <!-- Navigation arrows -->
                    <button class="carousel-btn carousel-btn-prev">
                        <span>&#8249;</span>
                    </button>
                    <button class="carousel-btn carousel-btn-next">
                        <span>&#8250;</span>
                    </button>
                </div>
                
                <!-- Slide indicators -->
                <div class="carousel-indicators">
                    <button class="indicator active"></button>
                    <button class="indicator"></button>
                    <button class="indicator"></button>
                    <button class="indicator"></button>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">Project Overview</h2>
            <div class="text-content">
                <p>The Berkeley mixed reality stroke rehabilitation project is under Professor Sanjit A. Seshia's research group and partners with UCSF and Stanford hospitals. The goal of the project is to empower therapists and patients to conduct therapy sessions remotely using MR headsets like the Meta Quest 3 and create tailored exercise programs that report patient progress to therapists. This fulfills a vital need as patient waitlists for in-person therapy can last for months and many patients face locational barrier getting to clinics. My role as a researcher in the project is to lead and project manage the frontend, backend, and Unity applications.</p>
                
                <p>As project lead, I managed a team of 3-5 developers, including both student researchers and professional developers, coordinating tasks and timelines to ensure milestones were met. I designed and implemented systems across backend (Go, AWS), frontend (React, Typescript), and Unity (C#) codebases, integrating Agora video calling, Clerk authentication, AWS App runner & databases, and multi-provider AI (Gemini, OpenAI, Bedrock). I also prototyped the novel rehabilitation system using multimodal AI to generate and monitor personalized therapy exercises.</p>

                <h3>Key Features</h3>
                <ul>
                    <li>Remote therapy sessions conducted via video call between therapists on the web portal and patients on MR headset, providing therapists with a first-person view, 3D environment visualization, and real-time pose reconstruction.</li>
                    <li>Exercise programs created using natural language worksheets or recorded during therapy sessions, tailored to individual patient capabilities with automatic progress logging for therapist review.</li>
                    <li>Multimodal AI system that evaluates exercise performance using both real and virtual objects, providing automated feedback and adjustments.</li>
                    <li>End-to-end HIPAA compliant system ensuring patient data privacy and security throughout therapy sessions.</li>
                </ul>
        </div>

        <div class="content-section">
            <h2 class="section-title">Results & Future Work</h2>

            <!-- TEXT WITH IMAGE (Image on Left) -->
            <div class="text-with-image image-left">
                <div class="image-container">
                    <div class="placeholder"><img src="..." alt="Photo"></div>
                    <div class="caption">...</div>
                </div>
                <div class="text-content">
                    <p>The project has completed initial workshop prototype studies, with full patient deployment studies scheduled for Spring 2026 at UCSF and Stanford thereafter.</p>
                </div>
            </div>

            <div class="stats-grid">
                <div class="stat-item">
                    <span class="stat-number">...</span>
                    <div class="stat-label">...</div>
                </div>

            </div>
        </div>
        
        <!-- PARTICIPANT FEEDBACK -->
         <div class="quote-block">
            "... I liked the structured exercises and having the audio and [captions] walk me through the exercises... The menu was easy to navigate."
            <div class="quote-author">— Patient Workshop Participant</div>
        </div>
        <div class="quote-block">
            "... I see the need for something like this, I don't have anyone to drive me to therapy that can take [an hour] to get to so I stopped going."
            <div class="quote-author">— Patient Workshop Participant</div>
        </div>

        <h3 class="section-title">Collaborators</h3>
                <div class="text-content">
                    <p>
                        <strong>Sanjit A. Seshia</strong> - UC Berkeley Faculty, Principle Investigator<br>
                        <strong>Edward Kim</strong> - UC Berkeley Post Doc, Project Facilitator.<br>
                        <strong>Erik Nelson</strong> - Berkeley EECS Alumi, Head Backend Developer<br>
                        <strong>Alton Sturgis</strong> - Berkeley EECS Alumi, Unity Developer<br>
                        <strong>Junwei Lu</strong> - Berkeley EECS Student Researcher, Backend Developer<br>
                        <strong>Andrew Lau</strong> - Berkeley EECS Student Researcher, Frontend Developer<br>
                        <strong>Jaansi Parsa</strong> - Berkeley EECS, Researcher, Frontend Developer<br>
                        <strong>Lucy W</strong> - Berkeley EECS Alumni, Researcher, Frontend Developer<br>
                        <strong>Caesar Li</strong> - Berkeley EECS, Student Researcher, Unity Developer<br>
                        <strong>Yash Prakash</strong> - Software Engineer, Researcher, Unity Developer<br>
                    </p>
                </div>

        <!-- DIVIDER FOR DEEPER CONTENT -->
        <div style="border-top: 2px solid #ddd; margin: 60px 0 40px 0;"></div>

        <div class="content-section">
            <h2 class="section-title">Technical Deep Dive</h2>
            <div class="text-content">
                <h3>Remote Therapy Call</h3>
                <p>
                    The remote therapy call system leverages Agora's real-time video SDK to handle communication between therapist on the Webportal and patients using Quest 3 headset. The first person view from the headset provides a unique perspective for therapists, espectially ocupational therapists, to assest patient's movement while completing everyday tasks. However, since it's hard to fully understand the patient's movement from just a first person view, we also provide a 3D reconstruction WebGL companion app to show a simplified patient enviroment and body pose estimation. This also allows therapists to place virtual objects in the patient's enviroment for conducting exercises.
                </p>
                
                <!-- DOUBLE IMAGE -->
                <div class="double-image double-image-fixed">
                    <div class="image-item">
                        <img src="images/stroke-rehab/therapist view.png" alt="">
                        <div class="caption">Therapist Webportal View</div>
                    </div>
                    <div class="image-item">
                        <img src="images/stroke-rehab/patient view.png" alt="">
                        <div class="caption">Patient Headset View.</div>
                    </div>
                </div>

                <div class="single-image">
                    <div class="placeholder">[Image Description]</div>
                    <div class="caption">Video showing therapist placing down virtual circle and patient seeing it in their enviroment.</div>
                </div>

                <h3>Exercise Programs</h3>
                <p>
                    ... natural lang -> program -> uses body pose estimation and multimodal ai to evaluate performance ...
                </p>
                <div class="single-image">
                    <div class="placeholder">[Image Description]</div>
                    <div class="caption">Diagram showing how exercise programs are generated.</div>
                </div>

                <p>
                    ... examples ...
                </p>
                <div class="single-image">
                    <div class="placeholder">[Image Description]</div>
                    <div class="caption">Video showcasing exercise program examples.</div>
                </div>

                <div class="text-with-image">
                <div class="text-content">
                    <h3>Accessibility</h3>
                    <p>
                        ...
                    </p>
                </div>
                <div class="image-container">
                    <img src="images/stroke-rehab/QR Code Scanning.gif" alt="">
                    <div class="caption">Login Token Encoded in QR Code</div>
                </div>
            </div>
            </div>
        </div>
</div>

<script src="carousel.js"></script>

</body>
</html>